---
title: "Binary distance calculations for missing data with Quarto"
format:
    live-revealjs:
        slide-number: true
        show-slide-number: speaker
        chalkboard: true
        code-line-numbers: true
        preview-links: true
        width: 1350
        height: 700
        logo: assets/images/UL_logo.jpg
        footer: "[Source code](https://github.com/michaelplynch/binarydists)"
author: "Michael Lynch"
from: markdown+emoji
engine: knitr
editor: source
---

{{< include ./_extensions/r-wasm/live/_knitr.qmd >}}

##  {background-image="assets/images/UL_slides_template.png"}

Today's lab meeting:

::: nonincremental
-   Demonstrate and provide template for reproducible & interactive presentations with Quarto
-   Introduce algorithm complexity and vectorisation
-   Matrix multiplication for binary and missing data
:::

# Quarto basics

## Quarto presentations

Rendered similar to .rmd/.qmd docs/websites/books etc.

Multiple rendering formats (Powerpoint, beamer, revealjs)

Can be hosted on Github pages (see source code)

More info [here](https://quarto.org/docs/presentations/revealjs/#footer-logo)

## Code and output can be rendered similar to .Rmd/.Qmd docs {.scrollable}

- Any language compatible was code chunks in RStudio can be used

R: 

```{r echo=TRUE}

print("here's some random r code")

```

Python:

```{python echo=TRUE}

print('Hello, world!')

```

And some good ol' bash because why not?

````{bash echo=TRUE}

echo " Hello World "
pwd
whoami 
````

## Line highlighting draw attention to specific parts of code. (sort of)

IMO this aspect still lacks finesse (or else I just haven't figured it out yet, very possible)

````{r}
#| echo: true
#| code-line-numbers: "|1|2|3|4"

x<-1:5
y=sqrt(x^2)
x==y
identical(x,y)
class(x)
class(y)
````

## Other formatting options look a bit messy too?

````{r}
#| echo: true
#| output-location: column
#| code-line-numbers: "|1|2|3|4"

x<-1:5
y=sqrt(x^2)
x==y
identical(x,y)
class(x)
class(y)
````

Maybe there's a better way to use one chunk per output instead...

## We can also include interactive code using quarto-live {.scrollable}

Runs in the browser through [WebAssembly](https://webassembly.org/) and [Quarto-live](https://r-wasm.github.io/quarto-live/)

```{webr}
#| echo: true
#| output-location: column
# test some of you own code here :) 

cat('You can write some of your own code, and reset if needed.\nOther functionality can be used for creating grading for teaching.')

cat('Quarto-live uses webR for interactive R')
```


```{pyodide include=FALSE}
for x in range(3):
  print(x ** 2)

print('Quarto-live uses pyodide for interactive python')
```


## How about some interactive plots?

````{r}
#| fig-height: 8
#| fig-width: 20
library(plotly)
fig <- plot_ly(z = volcano, type = "heatmap")

fig

````




# Algorithm complexity, benchmarking and vectorisation

## Complexity

::: columns
::: {.column width="50%"}
-   Mainly concerned with how an algorithm scales in terms of runtime or memory (among other things) as the input size increases.

-   Uses 'Big O' notation where n is the size of the input e.g. O(n), O(n\^2)

-   Big O notation doesn't capture the actual time/memory usage, just it's relationship with the size of input data
:::

::: {.column width="50%"}
```{r fig.height=6,fig.width=6}

n<-1:10
df<-data.frame(n=n,nsqrd=n^2,nexp=2^n,nlogn=n*log(n))
library(ggpubr)
ggline(df,x='n',y=c('nexp','nsqrd','nlogn'),merge = TRUE) + ggtitle('Common scaling for different 1000-100,000')

```
:::
:::

## Benchmarking {.scrollable}

```{webr}

#print(Sys.time())
#system.time(Sys.sleep(2))

#tictoc::tic()
#Sys.sleep(2)
#res<-tictoc::toc()
#res

#microbenchmark::microbenchmark('wait1'={Sys.sleep(0.1)},
#                               'wait2'={Sys.sleep(0.1)},
#                               times=10)
```

## Vectorisation {.scrollable}

So, we now have introduced some concepts for understanding and measuring the efficiency of our code. Now let's look at a simple application of vectorisation.

Loops get a bad rep in R for a couple of reasons.

```{r}
#| echo: true

n=100
x=1:n

microbenchmark::microbenchmark('vec'={y=x^2},'loop'={y=c();for(i in seq_along(x)){y[i]<-x[i]^2};y},times = 1000,unit = 's')

rbenchmark::benchmark('vec'={y=x^2},'loop'={y=c();for(i in seq_along(x)){y[i]<-x[i]^2};y},replications  = 1000)
```

## Lets take a look at scaling {.scrollable}

```{r}
library(rbenchmark)
library(microbenchmark)
ns<-seq(2000,20000,2000)
tot<-c()
for (i in seq_along(ns)) {
  n<-ns[i]
  mb<-microbenchmark::microbenchmark('vec'={y=x^2},'loop'={y=c();for(i in seq_along(x)){y[i]<-x[i]^2}},times = 100,unit = 's',setup = {x=1:n})
  #print(i)
  mn<-summary(mb)[,'median']
  tot<-rbind(tot,mn)
}

df<-data.frame(n=ns,vec=tot[,1],loop=tot[,2])
#head(df)
library(ggpubr)
library(gridExtra)
grid.arrange(ggline(df,x='n',y=c('vec')),ggline(df,x='n',y=c('loop')),ncol=2)
```

# Adapting binary distance measures for missing data


## Intro to binary data {.scrollable}

-   Binary data is represented as either 0 or 1 and has many applications

-   We will try to leverage useful properties of binary data to classify SNPs


-   Numerical output buttttt not really. No real reason 0 should be considreed closer to 1 than 3. Just a way to code it.

## SNPs simulated heatmap {.scrollable}

```{r}
#| fig-height: 5
#| fig-width: 10

set.seed(1)
vartrix_snps_sim<-matrix(sample(c(0,1,2,3),20,replace=TRUE),ncol=2)
head(vartrix_snps_sim)

snps2<-vartrix_snps_sim
snps2[snps2 %in% c(1,0)]<-0
snps2[snps2 %in% c(2,3)]<-1
mode(vartrix_snps_sim)<-'character'

snps3<-snps2
snps3[vartrix_snps_sim==0]<-NA
library(ComplexHeatmap)
Heatmap(vartrix_snps_sim,cluster_rows=FALSE,cluster_columns=FALSE,column_title = 'cells',row_title = 'SNPs')
Heatmap(snps2,cluster_rows = FALSE,cluster_columns = FALSE,column_title = 'cells',row_title = 'SNPs')

table(snps2[,1],snps2[,2])

Heatmap(snps3,cluster_rows = FALSE,cluster_columns = FALSE,column_title = 'cells',row_title = 'SNPs')

table(snps3[,1],snps3[,2])
```

## Binary distance measures {.scrollable}


|     | 1   | 0   |
|-----|-----|-----|
| 1   | a   | b   |
| 0   | c   | d   |

j=a/(a+b+c)

````{webr}

library(ade4)
?dist.binary

````


## Matrix multiplication (product)

[matrix multiplication wiki](https://en.wikipedia.org/wiki/Matrix_multiplication)

[matrix multiplicataion worked example khan academy](https://www.khanacademy.org/math/linear-algebra/matrix-transformations/composition-of-transformations/v/linear-algebra-matrix-product-examples)

a= m x t(m) 

b= (1-m) x t(m) 

c= m x t(1-m)

But this set up neglects missing data.
We extend this by multiplying each side of the equation (element wise) by an additional matrix such that 0=no read, 1= SNP in alt, ref, or both

## New implementation {.scrollable}


Create a second matrix to show missing data:

````{r}

snps4<-vartrix_snps_sim>0


Heatmap(snps3,cluster_rows=FALSE,cluster_columns = FALSE,column_title = 'cells',row_title = 'SNPs')

cat('goes to >>>')
Heatmap(snps4*1,cluster_rows = FALSE ,cluster_columns = FALSE,column_title = 'cells',row_title = 'SNPs')
````

## Let's revisit our distance matrix calc

where m is snp absent/present and p is read absent/present.

a = 1,1 = m x t(m) -> mp x t(mp)

b = 0,1 = (1-m) x t(m) -> (1-mp) x t(mp)

c = 1,0 = m x t(1-m) -> mp x t(1-mp)

## What do we see in practice?

No SNPs in common -> 0/0 -> NA (this is fine, we can just set these to distance=1 so they don't get included.)
 
But, with few SNPs in common, 0/1 or 0/2 etc. distances occur, but often not legit and impact nearest neighbour classification.

- Ideally we want to classify based on cells with most overlap.
- Could set a threshold but this may be arbitrary and dataset dependent (e.g. only look at cells with at least 50 SNPs overlap for classifying)

Solution?

Infer 'centroid' of each singlet, doublet cluster so information is shared across training data.

Perform nearest centroid type classification.



# Take-home messages

## Quarto + presentations

- reproducible (thumbs up)
- allows code highlighting, interactive plots, 
- great tool for teaching/workshops

- still some teething issues in formatting/aesthetics
- learning curve

## Development


- Benchmark, start with small units/bottlenecks
- think about how the code will need to scale, now and in the future
- revise your math :)

